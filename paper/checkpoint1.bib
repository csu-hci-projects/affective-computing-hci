@ARTICLE{911197,
  author={Cowie, R. and Douglas-Cowie, E. and Tsapatsoulis, N. and Votsis, G. and Kollias, S. and Fellenz, W. and Taylor, J.G.},
  journal={IEEE Signal Processing Magazine}, 
  title={Emotion recognition in human-computer interaction}, 
  year={2001},
  volume={18},
  number={1},
  pages={32-80},
  doi={10.1109/79.911197}
  }
  
@ARTICLE{GO2019304,
    title = {Humanizing chatbots: The effects of visual, identity and conversational cues on humanness perceptions},
    journal = {Computers in Human Behavior},
    volume = {97},
    pages = {304-316},
    year = {2019},
    issn = {0747-5632},
    doi = {https://doi.org/10.1016/j.chb.2019.01.020},
    url = {https://www.sciencedirect.com/science/article/pii/S0747563219300329},
    author = {Eun Go and S. Shyam Sundar},
    keywords = {Online chat agents, Message interactivity, Identity cue, Anthropomorphic visual cue, Compensation effect, Expectancy violation effect},
    abstract = {Chatbots are replacing human agents in a number of domains, from online tutoring to customer-service to even cognitive therapy. But, they are often machine-like in their interactions. What can we do to humanize chatbots? Should they necessarily be driven by human operators for them to be considered human? Or, will an anthropomorphic visual cue on the interface and/or a high-level of contingent message exchanges provide humanness to automated chatbots? We explored these questions with a 2 (anthropomorphic visual cues: high vs. low anthropomorphism) × 2 (message interactivity: high vs. low message interactivity) × 2 (identity cue: chat-bot vs. human) between-subjects experiment (N = 141) in which participants interacted with a chat agent on an e-commerce site about choosing a digital camera to purchase. Our findings show that a high level of message interactivity compensates for the impersonal nature of a chatbot that is low on anthropomorphic visual cues. Moreover, identifying the agent as human raises user expectations for interactivity. Theoretical as well as practical implications of these findings are discussed.}
}

 @book{picard_2000, 
    place={Cambridge, Massachusetts etc.}, 
    title={Affective computing}, publisher={MIT Press}, 
    author={Picard, Rosalind W.}, 
    year={2000}
} 

 @misc{czerwinski_hernandez_mcduff_2021, 
    title={Building an AI that feels}, url={https://spectrum.ieee.org/building-an-ai-that-feels}, 
    journal={IEEE Spectrum}, 
    publisher={IEEE Spectrum}, 
    author={Czerwinski, Mary and Hernandez, Javier and McDuff, Daniel}, 
    year={2021}, 
    month={Sep}} 


@article{doi:10.1287/isre.2021.1015,
    author = {Schanke, Scott and Burtch, Gordon and Ray, Gautam},
    title = {Estimating the Impact of “Humanizing” Customer Service Chatbots},
    journal = {Information Systems Research},
    volume = {32},
    number = {3},
    pages = {736-751},
    year = {2021},
    doi = {10.1287/isre.2021.1015},
    URL = {https://doi.org/10.1287/isre.2021.1015},
    eprint = {https://doi.org/10.1287/isre.2021.1015},
    abstract = { In this work, we investigate how applying human-like characteristics to customer service chatbots can influence retail outcomes. This is an important managerial question as creating effective chatbot experiences through messaging platforms has proven difficult for organizations. Often, chatbot developers apply characteristics such as giving a chatbot a human name, adding humor, and so on, without knowing how these features influence end user behavior. Implementing a field experiment in collaboration with a dual channel clothing retailer based in the United States, we automate a used clothing buy-back process, such that individuals engage with the retailer's autonomous chatbot to describe the used clothes they wish to sell, obtain a cash offer, and (if they accept) print a shipping label to finalize the transaction. We provide evidence that, in this retail setting, anthropomorphism is beneficial for transaction outcomes, but that it also leads to significant increases in consumers’ sensitivity to the offer amount. We argue that the latter effect occurs because, as a chatbot becomes more human-like, consumers shift to a fairness evaluation or negotiating mindset. }
}


